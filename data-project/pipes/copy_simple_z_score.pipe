DESCRIPTION >
	Named 'simple' since this does not make 10-second aggregations. 

This implements a simple algorith based on a time-series average and standard deviation over a minute-scale window of data. Each incoming data point, x, has a Z-Score calculated in this way:  

`zscore = (x - avg) / stddev`

Currently, this Pipe is based on two time windows: 
First, the statistics are calculated across the `_stats_time_window_minutes`.
Second, anomalies are scanned for using the `_anomaly_scan_time_window_seconds` window.

These parameters, along with the `_zscore_outlier_multiplier` setting, could be promoted to API Endpoint query parameters.


TOKEN "scheduled_copy_t_45b2ddee35524b37a4c70942e4a5a8f3" READ

NODE calculate_zscore
DESCRIPTION >
    Promote these to endpoint query parameters?

SQL >

    WITH stats AS (
        SELECT id,
            avg(value) AS average,
            stddevPop(value) AS std_dev
        FROM incoming_data
        WHERE timestamp between now() - interval 10 minute and now()
        GROUP BY id  
    )
    SELECT i.timestamp, 
         i.id, 
         i.value, 
         (i.value - stats.average)/stats.std_dev AS zscore,
         ROUND(stats.average,2) AS average,
         ROUND(stats.std_dev,2) AS std_dev,
         2 AS zscore_multiplier
    FROM incoming_data i
    JOIN stats s ON s.id = i.id
    WHERE timestamp BETWEEN now() - interval 30 second AND now()
    ORDER BY timestamp desc



NODE log
SQL >

    SELECT id,
       timestamp,
       value,
       'z-score' AS anomaly_type,
       concat('z-score: ',  substring(toString(zscore),1,6), ' | ', multiIf(zscore < (-1 * zscore_multiplier), 'low', zscore > zscore_multiplier, 'high','ok'),' | average: ', toString(average),' | std_dev: ', toString(std_dev)) AS note
    FROM calculate_zscore
    WHERE zscore < (-1 * zscore_multiplier) OR zscore > zscore_multiplier 
    ORDER by timestamp DESC

TYPE copy
TARGET_DATASOURCE copy_log
COPY_SCHEDULE * * * * *


